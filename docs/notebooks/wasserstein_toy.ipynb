{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: Wasserstein distance estimation\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deel-ai/deel-torchlip/blob/master/docs/notebooks/wasserstein_toy.ipynb)\n",
    "\n",
    "In this notebook we estimate the Wasserstein distance through its Kantorovich-Rubinstein\n",
    "dual representation by using a 1-Lipschitz neural network.\n",
    "\n",
    "## 1. Wasserstein distance\n",
    "\n",
    "The Wasserstein distance measures the distance between two probability distributions.\n",
    "The Wikipedia article gives a more intuitive definition:\n",
    "\n",
    "> Intuitively, if each distribution is viewed as a unit amount of \"dirt\" piled on $M$,\n",
    "> the metric is the minimum \"cost\" of turning one pile into the other, which is assumed\n",
    "> to be the amount of dirt that needs to be moved times the mean distance it has to be\n",
    "> moved. Because of this analogy, the metric is known in computer science as the earth\n",
    "> mover's distance.\n",
    "\n",
    "Mathematically it is defined as\n",
    "\n",
    "$$\n",
    "W_1(\\mu,\\nu) = \\inf_{\\pi \\in \\Pi(\\mu,\\nu)}\\underset{x,z \\sim \\pi}{\\mathbb{E}}\\Vert{} \\textbf{x}-\\textbf{z} \\Vert{}\n",
    "$$\n",
    "\n",
    "where $\\Pi(\\mu,\\nu)$ is the set of all probability measures on $\\Omega\\times \\Omega$\n",
    "with marginals $\\mu$ and $\\nu$. In most case this equation is not tractable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the required library deel-torchlip (uncomment line below)\n",
    "# %pip install -qqq deel-torchlip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Parameters input images\n",
    "\n",
    "We illustrate this on a synthetic image dataset where the $W_1$ distance is known.\n",
    "\n",
    "Our synthetic dataset contains images with black or white squares, allowing us to check\n",
    "if the computed Wasserstein distance is correct. The two distributions are\n",
    "\n",
    "- the set of black images (all 0),\n",
    "- the set of images with a square on it (all 0, with a square of -1 or +1 in the\n",
    "  middle).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "size = (64, 64)\n",
    "frac = 0.3  # proportion of the center square\n",
    "\n",
    "\n",
    "def generate_toy_images(shape: Tuple[int, int], frac: float = 0, value: float = 1):\n",
    "    \"\"\"\n",
    "    Generates a single image.\n",
    "\n",
    "    Args:\n",
    "        shape: Shape of the output image.\n",
    "        frac: Proportion of the center rectangle.\n",
    "        value: Value assigned to the center rectangle.\n",
    "    \"\"\"\n",
    "    img = np.zeros(shape)\n",
    "    if frac == 0:\n",
    "        return img\n",
    "\n",
    "    frac = frac ** 0.5\n",
    "\n",
    "    l = int(shape[0] * frac)\n",
    "    ldec = (shape[0] - l) // 2\n",
    "    w = int(shape[1] * frac)\n",
    "    wdec = (shape[1] - w) // 2\n",
    "\n",
    "    img[ldec : ldec + l, wdec : wdec + w] = value\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def generator(batch_size: int, shape: Tuple[int, int], frac: float):\n",
    "    \"\"\"\n",
    "    Creates an infinite generator that generates batch of images. Half of the batch\n",
    "    comes from the first distribution (only black images), while the remaining half\n",
    "    comes from the second distribution.\n",
    "\n",
    "    Args:\n",
    "        batch_size: Number of images in each batch.\n",
    "        shape: Shape of the image.\n",
    "        frac: Fraction of the square to set \"white\".\n",
    "\n",
    "    Returns:\n",
    "        An infinite generator that yield batch of the given size.\n",
    "    \"\"\"\n",
    "\n",
    "    pwhite = generate_toy_images(shape, frac=frac, value=1)\n",
    "    nwhite = generate_toy_images(shape, frac=frac, value=-1)\n",
    "\n",
    "    nblack = batch_size // 2\n",
    "    nsquares = batch_size - nblack\n",
    "    npwhite = nsquares // 2\n",
    "    nnwhite = nsquares - npwhite\n",
    "\n",
    "    batch_x = np.concatenate(\n",
    "        (\n",
    "            np.zeros((nblack,) + shape),\n",
    "            np.repeat(pwhite[None, ...], npwhite, axis=0),\n",
    "            np.repeat(nwhite[None, ...], nnwhite, axis=0),\n",
    "        ),\n",
    "        axis=0,\n",
    "    )\n",
    "    batch_y = np.concatenate((np.zeros((nblack, 1)), np.ones((nsquares, 1))), axis=0)\n",
    "\n",
    "    while True:\n",
    "        yield batch_x, batch_y\n",
    "\n",
    "\n",
    "def display_image(ax, image, title: str = \"\"):\n",
    "    ax.imshow(image, cmap=\"gray\")\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider images of size 64x64, and an inner square that covers about 30% of the image. \n",
    "We can manually compute the $W_1$ distance between the two sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2-Norm, black vs. 'negative' white -> 35.0\n",
      "L2-Norm, black vs. 'positive' white -> 35.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1512x504 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img1 = generate_toy_images(size, 0)\n",
    "img2 = generate_toy_images(size, frac, value=-1)\n",
    "img3 = generate_toy_images(size, frac, value=1)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(21, 7))\n",
    "\n",
    "display_image(axs[0], img1, \"black (label = -1)\")\n",
    "display_image(axs[1], img2, \"'negative' white (label = 1)\")\n",
    "display_image(axs[2], img3, \"'positive' white (label = 1)\")\n",
    "\n",
    "print(\"L2-Norm, black vs. 'negative' white -> {}\".format(np.linalg.norm(img2 - img1)))\n",
    "print(\"L2-Norm, black vs. 'positive' white -> {}\".format(np.linalg.norm(img3 - img1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the distance between the fully black image and any of the two images with an inner square is $35$, and these are the only images in our distributions, the $W_1$ distance between the two distances is also $35$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Kantorovich-Rubinstein dual formulation\n",
    "\n",
    "The Kantorovich-Rubinstein (KR) dual formulation of the Wasserstein distance is\n",
    "\n",
    "$$ W_1(\\mu, \\nu) = \\sup_{f \\in Lip_1(\\Omega)} \\underset{\\textbf{x} \\sim \\mu}{\\mathbb{E}}\n",
    "\\left[f(\\textbf{x} )\\right] -\\underset{\\textbf{x} \\sim \\nu}{\\mathbb{E}}\n",
    "\\left[f(\\textbf{x} )\\right]. $$\n",
    "\n",
    "This states the problem as an optimization problem over the space of 1-Lipschitz\n",
    "functions. We can estimate this by optimizing over the space of 1-Lipschitz neural\n",
    "networks.\n",
    "\n",
    "- [1] C. Anil, J. Lucas, et R. Grosse, \"Sorting out Lipschitz function approximation\",\n",
    "  arXiv:1811.05381, nov. 2018.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Building a 1-Lipschitz model\n",
    "\n",
    "In this section, we use the `deel.torchlip` (short `torchlip`) to build a 1-Lipschitz\n",
    "network. The `torchlip` library is the PyTorch equivalent of\n",
    "[`deel-lip`](https://github.com/deel-ai/deel-lip). In this example, we use two\n",
    "1-Lipschitz layers and a special activation function:\n",
    "\n",
    "- `SpectralLinear` uses spectral normalization to force the maximum singular value of\n",
    "  the weight matrix to be one, followed by Bjorck normalization to force all singular\n",
    "  values to be 1. After convergence, all singular values are equal to 1 and the linear\n",
    "  operation is 1-Lipschitz. The `SpectralLinear` class also uses orthogonal\n",
    "  initialization for the weight (see `torch.init.orthogonal_`).\n",
    "- `FrobeniusLinear` simply divides the weight matrix by its Frobenius norm. We only use\n",
    "  it for the last layer because this layer has a single output. Similar to\n",
    "  `SpectralLinear`, the weights are initialized using orthogonal initialization.\n",
    "- We use `FullSort` activation, which is a 1-Lipschitz activation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): ParametrizedSpectralLinear(\n",
       "    in_features=4096, out_features=128, bias=True\n",
       "    (parametrizations): ModuleDict(\n",
       "      (weight): ParametrizationList(\n",
       "        (0): _SpectralNorm()\n",
       "        (1): _BjorckNorm()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): FullSort()\n",
       "  (3): ParametrizedSpectralLinear(\n",
       "    in_features=128, out_features=64, bias=True\n",
       "    (parametrizations): ModuleDict(\n",
       "      (weight): ParametrizationList(\n",
       "        (0): _SpectralNorm()\n",
       "        (1): _BjorckNorm()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (4): FullSort()\n",
       "  (5): ParametrizedSpectralLinear(\n",
       "    in_features=64, out_features=32, bias=True\n",
       "    (parametrizations): ModuleDict(\n",
       "      (weight): ParametrizationList(\n",
       "        (0): _SpectralNorm()\n",
       "        (1): _BjorckNorm()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (6): FullSort()\n",
       "  (7): ParametrizedFrobeniusLinear(\n",
       "    in_features=32, out_features=1, bias=True\n",
       "    (parametrizations): ModuleDict(\n",
       "      (weight): ParametrizationList(\n",
       "        (0): _FrobeniusNorm()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from deel import torchlip\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "wass = torchlip.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torchlip.SpectralLinear(np.prod(size), 128),\n",
    "    torchlip.FullSort(),\n",
    "    torchlip.SpectralLinear(128, 64),\n",
    "    torchlip.FullSort(),\n",
    "    torchlip.SpectralLinear(64, 32),\n",
    "    torchlip.FullSort(),\n",
    "    torchlip.FrobeniusLinear(32, 1),\n",
    ").to(device)\n",
    "\n",
    "wass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Training a 1-Lipschitz network with KR loss\n",
    "\n",
    "We now train this neural network using the Kantorovich-Rubinstein formulation for the\n",
    "Wasserstein distance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 16/16 [00:00<00:00, 32.56it/s, loss=-22.727377]\n",
      "Epoch 2/10: 100%|██████████| 16/16 [00:00<00:00, 104.26it/s, loss=-32.414299]\n",
      "Epoch 3/10: 100%|██████████| 16/16 [00:00<00:00, 103.01it/s, loss=-34.711800]\n",
      "Epoch 4/10: 100%|██████████| 16/16 [00:00<00:00, 102.35it/s, loss=-34.961674]\n",
      "Epoch 5/10: 100%|██████████| 16/16 [00:00<00:00, 104.20it/s, loss=-34.989662]\n",
      "Epoch 6/10: 100%|██████████| 16/16 [00:00<00:00, 104.12it/s, loss=-34.993656]\n",
      "Epoch 7/10: 100%|██████████| 16/16 [00:00<00:00, 104.29it/s, loss=-34.993637]\n",
      "Epoch 8/10: 100%|██████████| 16/16 [00:00<00:00, 104.32it/s, loss=-34.994102]\n",
      "Epoch 9/10: 100%|██████████| 16/16 [00:00<00:00, 102.74it/s, loss=-34.994442]\n",
      "Epoch 10/10: 100%|██████████| 16/16 [00:00<00:00, 103.46it/s, loss=-34.995232]\n"
     ]
    }
   ],
   "source": [
    "from deel.torchlip import KRLoss\n",
    "from tqdm import trange\n",
    "\n",
    "batch_size = 16\n",
    "n_epochs = 10\n",
    "steps_per_epoch = 256\n",
    "\n",
    "# Create the image generator:\n",
    "g = generator(batch_size, size, frac)\n",
    "\n",
    "kr_loss = KRLoss()\n",
    "optimizer = torch.optim.Adam(lr=0.01, params=wass.parameters())\n",
    "\n",
    "n_steps = steps_per_epoch // batch_size\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    tsteps = trange(n_steps, desc=f\"Epoch {epoch + 1}/{n_epochs}\")\n",
    "    for _ in tsteps:\n",
    "        data, target = next(g)\n",
    "        data, target = (\n",
    "            torch.tensor(data).float().to(device),\n",
    "            torch.tensor(target).float().to(device),\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        output = wass(data)\n",
    "        loss = kr_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tsteps.set_postfix({\"loss\": \"{:.6f}\".format(loss)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the loss converges to the value $35$ which is the $W_1$ distance between\n",
    "the two distributions (with and without squares).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deel-pt1.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
